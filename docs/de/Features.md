# Funktionalit√§ten

## Mehrere KI-Personas

Das System umfasst vier unterschiedliche KI-Personas mit eigenen Charakteren. Alle Personas nutzen das gleiche zugrundeliegende Sprachmodell, unterscheiden sich jedoch durch spezielle System-Prompts, die ihren Sprachstil und Ton festlegen:

- **Leah** ‚Äì empathisch und freundlich  
- **Doris** ‚Äì sarkastisch und schlagfertig humorvoll  
- **Peter** ‚Äì faktenorientiert, analytisch und sachlich  
- **Popcorn** ‚Äì verspielt und kindgerecht (Katzen-Persona)  

Die Auswahl der Persona erfolgt entweder beim Start (Terminal-UI) oder √ºber die Weboberfl√§che. Jede Persona reagiert im entsprechenden Stil auf Nutzeranfragen.

## Benutzeroberfl√§chen (UI)

Zwei verschiedene Benutzeroberfl√§chen stehen zur Verf√ºgung, ausw√§hlbar √ºber die Konfiguration (`ui.type`):

- **Terminal-UI** ‚Äì Konsolenbasierte Chat-Anwendung mit farbig hervorgehobenen Rollen (Nutzer/KI). Bei Start wird die gew√ºnschte Persona per Men√º ausgew√§hlt. Nutzereingaben werden direkt in der Konsole eingegeben, und die KI-Antwort erscheint tokenweise gestreamt. Es gibt einfache Befehle wie `exit` zum Beenden und `clear` f√ºr einen neuen Chatverlauf.
- **Web-UI** ‚Äì Webbasierte Oberfl√§che (Gradio), die im Browser verf√ºgbar ist. Sie bietet eine grafische Persona-Auswahl (mit Avatar-Bildern) und ein Chat-Fenster f√ºr die Unterhaltung. Die KI-Antwort wird hier live im Verlauf angezeigt, w√§hrend sie generiert wird. Die Web-UI ist im lokalen Netzwerk zug√§nglich und erm√∂glicht ein komfortables Chat-Erlebnis √ºber HTTP.

Optional kann ein **Ask-All/Broadcast-Modus** aktiviert werden (`ui.experimental.broadcast_mode: true`). Dann l√§sst sich eine Frage parallel an alle Personas richten ‚Äì im Terminal √ºber die Ask-All-Option im Startmen√º, in der Web-UI √ºber die Ask-All-Kachel mit Ergebnis-Tabelle f√ºr alle Antworten.

Zus√§tzlich kann `ui.type` auch auf `null` gesetzt werden, um ausschlie√ülich die API zu betreiben; die Web-UI unterst√ºtzt au√üerdem einen optionalen Gradio-Share-Link mit Zugangsdaten aus `ui.web.share_auth`.

## One-Shot API

Parallel zur UI kann das System auch √ºber eine REST-API angesprochen werden (z.‚ÄØB. f√ºr Integrationen oder Tests). Ein FastAPI-Server stellt einen **`/ask`-Endpoint** bereit, √ºber den per HTTP-POST einzelne Fragen gestellt werden k√∂nnen. Die Anfrage nimmt ein JSON entgegen (mit Feldern f√ºr die **Frage** und die gew√ºnschte **Persona**) und liefert die KI-Antwort als JSON-Antwort zur√ºck. Zus√§tzlich existiert ein einfacher **`/health`-Endpoint** f√ºr Health-Checks. Diese API erm√∂glicht es, die KI-Funktionalit√§t in externe Anwendungen einzubinden oder automatisiert zu nutzen.

## Wikipedia-Integration

Um fundierte Antworten zu erm√∂glichen, kann das System bei Wissensfragen automatisch **Wikipedia-Wissen einbinden** (optional konfigurierbar). Dabei kommen folgende Mechanismen zum Einsatz:

- **Automatischer Wissensabruf:** Aus der Nutzerfrage wird mittels spaCy-NLP das relevanteste Schlagwort extrahiert. Anschlie√üend sucht ein interner Wiki-Proxy nach einem passenden Wikipedia-Artikel ‚Äì je nach Einstellung entweder **offline** √ºber eine lokale Kiwix-Datenbank oder **online** √ºber die Wikipedia-API. Bei Offline-Modus kann der Kiwix-Server automatisch gestartet werden, sofern konfiguriert.  
- **Kontext-Erweiterung:** Findet der Wiki-Proxy einen Artikel, wird ein Ausschnitt (Snippet) daraus entnommen. Dieser Ausschnitt wird als zus√§tzliche *System*-Nachricht in den Chat-Kontext eingef√ºgt, bevor die KI antwortet. Die KI erh√§lt so gepr√ºfte Fakten als Kontext und kann pr√§zisere Antworten geben. In der Terminal-UI wird au√üerdem ein Hinweis-Icon (üïµÔ∏è) angezeigt, wenn ein Wikipedia-Snippet benutzt wurde. Bleibt die Suche ohne Treffer, wird dies durch eine kurze Hinweisnachricht vermerkt.
- **Mehrere Treffer nutzbar:** Erkennt der Keyword-Finder mehrere relevante Entit√§ten, k√∂nnen mehrere Snippets in den Prompt aufgenommen werden. Die Obergrenze steuert `wiki.max_wiki_snippets` (Standard: 2), sodass der Kontext gezielt erweitert werden kann, ohne zu √ºberladen.

## Logging und Tests

Stabile Nutzung wird durch umfangreiches Logging und automatische Tests unterst√ºtzt:

- **Chat-Logging:** Jede Unterhaltung wird in einer JSON-Datei (im Ordner `logs/`) mitprotokolliert. Darin werden Zeitstempel, verwendetes Modell, Persona sowie alle Nutzer- und KI-Nachrichten festgehalten. Zus√§tzlich schreibt die Anwendung fortlaufend ein System-Logfile (mit Pr√§fix `yulyen_ai_...`), das interne Abl√§ufe und Debug-Informationen (Info/Fehler) enth√§lt.  
- **Wiki-Proxy Logging:** Der Wikipedia-Proxy-Dienst f√ºhrt eigene Logdateien √ºber die Artikelanfragen und Ergebnisse. Dadurch lassen sich Wiki-Zugriffe und etwaige Fehler nachvollziehen, getrennt vom Haupt-Chat-Log.  
- **Automatisierte Tests:** Eine Sammlung von Pytest-Tests (`tests/` Verzeichnis) pr√ºft zentrale Funktionen des Systems. Beispielsweise wird getestet, ob die Personas korrekt initialisiert werden, ob der Sicherheits-Filter greift und ob wiederholbare Antworten (z.‚ÄØB. gleiche Witze von Doris) konsistent bleiben. Diese Tests helfen, Regressionen zu vermeiden und die Zuverl√§ssigkeit der KI-Orchestrierung sicherzustellen.

## Sicherheitsmechanismen

Das Projekt verf√ºgt √ºber einen einfachen integrierten **Security-Guard** (`BasicGuard`), der Eingaben und Ausgaben auf problematische Inhalte pr√ºft:

- **Prompt Injection Schutz:** Benutzer-Eingaben werden auf Muster √ºberpr√ºft, die auf Versuch einer *Prompt Injection* hindeuten (z.‚ÄØB. Anweisungen, vorherige Regeln zu ignorieren). Wird ein solcher Versuch erkannt, unterbricht der Guard den normalen Ablauf ‚Äì anstelle einer KI-Antwort erh√§lt der Nutzer einen Hinweis, dass die Anfrage abgelehnt wurde. Die potenziell sch√§dliche Eingabe wird nicht an das Sprachmodell weitergeleitet.  
- **PII-Filterung:** Der Guard erkennt in generierten KI-Antworten pers√∂nliche Daten (*Personally Identifiable Information*, z.‚ÄØB. E-Mail-Adressen, Telefonnummern) und ersetzt diese vorsorglich durch eine Standardwarnung. So wird verhindert, dass private oder sensible Informationen ungefiltert im Chat erscheinen.  
- **Output-Blockliste:** Bestimmte vertrauliche Schl√ºssel oder Tokens (z.‚ÄØB. API-Schl√ºssel im Format `sk-...`) werden ebenfalls erkannt. Sollte die KI derartige Sequenzen produzieren, wird die Ausgabe vollst√§ndig blockiert, um ein Leaken von Geheimnissen zu vermeiden. Im Ergebnis sieht der Nutzer dann lediglich eine allgemeine Warnung statt des gef√§hrlichen Inhalts.

Diese Pr√ºfungen greifen bereits w√§hrend des Streamings: Tokens werden laufend kontrolliert, bei Bedarf maskiert und bei blockierten Sequenzen sofort durch eine Sicherheitswarnung ersetzt.

## Erweiterbarkeit und Experimente

Die Architektur von *Yul Yen‚Äôs AI Orchestra* ist darauf ausgelegt, zuk√ºnftige Erweiterungen und Verbesserungen zu erm√∂glichen:

- **Modulare Architektur:** Das System kapselt den LLM-Zugriff hinter klar definierten Schnittstellen. Beispielsweise ist die Anbindung an das Sprachmodell √ºber die abstrakte Klasse `LLMCore` gel√∂st. Dies erlaubt es, das Backend einfach auszutauschen (z.‚ÄØB. ein anderer Modellserver statt Ollama, oder Verwendung des Dummy-LLM f√ºr Tests), ohne den Rest der Anwendung anzupassen. Auch neue Personas lassen sich durch Erg√§nzung der Konfiguration leicht hinzuf√ºgen.  
- **LoRA-Finetuning (PoC):** Erste Experimente zur Modellverfeinerung existieren als Proof-of-Concept, werden jedoch aus Platzgr√ºnden nicht im Standard-Repository mitgeliefert. Intern zeigt ein kleines **LoRA-Finetuning**-Beispiel (basierend auf [PEFT/QLoRA](https://github.com/huggingface/peft)), wie ein kompakter Adapter f√ºr die Persona Doris mit ca. 200 Frage-Antwort-Paaren trainiert wurde. Die zugeh√∂rigen Trainingsskripte und Testl√§ufe dienen ausschlie√ülich Demonstrationszwecken und sind nicht in den Hauptbetrieb integriert. Interessierte k√∂nnen sich bei den Maintainer:innen melden, um Details oder Zugang zu den Materialien zu erhalten.
- **Zuk√ºnftige Features:** Das Projekt hat bereits eine Roadmap f√ºr weitere Ideen. Geplant sind u.‚ÄØa. die Integration von Werkzeugen (*Tool Use* wie Websuche oder Rechner), Sprach-Ein-/Ausgabe (Speech-to-Text, Text-to-Speech) sowie ein verbesserter Umgang mit langen Chats durch *Retrieval-Augmented Generation* (z.‚ÄØB. automatisches Zusammenfassen alter Chat-Teile durch einen virtuellen Assistenten namens "Karl"). Die aktuelle Codebasis bildet eine einfache, erweiterbare Grundlage, auf der solche Features in Zukunft aufsetzen k√∂nnen.

siehe auch: [backlog.md](../../backlog.md)
